{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "from pymystem3 import Mystem\n",
    "from itertools import chain\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from scipy import optimize\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создадим отсортированный словарь слов в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1997/1997 [00:03<00:00, 543.24it/s]\n"
     ]
    }
   ],
   "source": [
    "wordCount_news = {}\n",
    "with open('ru.txt', 'r') as f:\n",
    "    lines = [re.sub(\"[^а-я\\s]\", \"\", line.lower()) for line in f.readlines()]\n",
    "lines = [re.sub(\"\\s+\", \" \", line).strip() for line in lines]\n",
    "stemmer = Mystem()\n",
    "words = chain.from_iterable([[word for word in stemmer.lemmatize(line) if re.match('[а-я]+', word)] for line in tqdm(lines)])\n",
    "for word in words:\n",
    "    if word.isalpha():\n",
    "        if word in wordCount_news:\n",
    "            wordCount_news[word.lower()] += 1\n",
    "        else:\n",
    "            wordCount_news[word.lower()] = 1\n",
    "sortedWordCount_news = collections.OrderedDict(reversed(sorted(wordCount_news.items(), key= lambda t : t[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18130/18130 [00:19<00:00, 936.22it/s] \n"
     ]
    }
   ],
   "source": [
    "wordCount_tolstoj = {}\n",
    "with open('tolstoj_lew_nikolaewich-text_0080.txt', 'r') as f:\n",
    "    lines = [re.sub(\"[^а-я\\s]\", \"\", line.lower()) for line in f.readlines()]\n",
    "lines = [re.sub(\"\\s+\", \" \", line).strip() for line in lines]\n",
    "stemmer = Mystem()\n",
    "words = chain.from_iterable([[word for word in stemmer.lemmatize(line) if re.match('[а-я]+', word)] for line in tqdm(lines)])\n",
    "for word in words:\n",
    "    if word.isalpha():\n",
    "        if word in wordCount_tolstoj:\n",
    "            wordCount_tolstoj[word.lower()] += 1\n",
    "        else:\n",
    "            wordCount_tolstoj[word.lower()] = 1\n",
    "sortedWordCount_tolstoj = collections.OrderedDict(reversed(sorted(wordCount_tolstoj.items(), key= lambda t : t[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logL(a, words):\n",
    "    N = len(words)\n",
    "    c = 1.0/np.sum([(1.0/k)**a for k in range(1, N+1)])\n",
    "    lnL = np.log(c) - a*np.mean(np.log([words[x] for x in words]))\n",
    "    return lnL\n",
    "def maximaze_loglikelihood(words):\n",
    "    return optimize.minimize(lambda a: -logL(a, words), x0=[1.5]).x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_news = maximaze_loglikelihood(sortedWordCount_news)\n",
    "c_news = 1.0/np.sum([(1.0/k)**a_news for k in range(1, len(sortedWordCount_news)+1)])\n",
    "news_exp = np.array([c_news/k**a_news for k in range(1, len(sortedWordCount_news)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tolstoj = maximaze_loglikelihood(sortedWordCount_tolstoj)\n",
    "c_tolstoj = 1.0/np.sum([(1.0/k)**a_tolstoj for k in range(1, len(sortedWordCount_tolstoj)+1)])\n",
    "tolstoj_exp = np.array([c_tolstoj/k**a_tolstoj for k in range(1, len(sortedWordCount_tolstoj)+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка гипотез черех хи-квадрат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=6.01074109462997, pvalue=1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tolstojs = np.array([sortedWordCount_tolstoj[key] for key in sortedWordCount_tolstoj])\n",
    "tolstojs = tolstojs/np.sum(tolstojs)\n",
    "chisquare(tolstojs, tolstoj_exp, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=42.89100031101945, pvalue=1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = np.array([sortedWordCount_news[key] for key in sortedWordCount_news])\n",
    "news = news/np.sum(news)\n",
    "chisquare(news, news_exp, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Видим, что данные гипотезе о распределении по закону Ципфа данным не противоречат "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим, можно ли утверждать, что параметры закона Ципфа для этих двух корпусов совпадают"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Power_divergenceResult(statistic=12.9330745781218, pvalue=1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chisquare(news, tolstoj_exp[:len(news)], ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверили через хи-квадрат, подставив параметр из другого распределения, видим, что данные гипотезе не противоречат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
